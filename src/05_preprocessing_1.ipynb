{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXhv1TGRHm2N"
      },
      "source": [
        "# Preprocessing Lanjutan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0idajq7wHpWx",
        "outputId": "56f82df6-f99e-4d2c-ba35-79cbded7260d"
      },
      "outputs": [],
      "source": [
        "!pip -q install category_encoders imbalanced-learn\n",
        "\n",
        "import numpy as np\n",
        "import category_encoders as ce\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"train_test_data.pkl\", \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "X_train = data[\"X_train\"]\n",
        "X_test  = data[\"X_test\"]\n",
        "y_train = data[\"y_train\"]\n",
        "y_test  = data[\"y_test\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3W0Tfs5o2Kij"
      },
      "outputs": [],
      "source": [
        "binary_features = [\n",
        "    'high_claim_without_witnesses',\n",
        "    'no_police_report_but_severe_damage',\n",
        "    'unknown_police_report_but_severe_damage',\n",
        "    'unknown_property_damage',\n",
        "    'unknown_collision_type',\n",
        "    'multi_vehicles_no_injury'\n",
        "]\n",
        "\n",
        "numeric_cols_raw = [\n",
        "    'months_as_customer', 'age', 'policy_annual_premium',\n",
        "    'capital-gains', 'capital-loss',\n",
        "    'incident_hour_of_the_day', 'number_of_vehicles_involved',\n",
        "    'bodily_injuries', 'witnesses',\n",
        "    'total_claim_amount', 'injury_claim',\n",
        "    'property_claim', 'vehicle_claim',\n",
        "    'auto_year', 'days_since_policy'\n",
        "] + binary_features  # biner ikut sebagai numerik juga\n",
        "\n",
        "categorical_cols_raw = [\n",
        "    'policy_state', 'policy_csl', 'insured_sex',\n",
        "    'insured_education_level', 'insured_occupation',\n",
        "    'insured_hobbies', 'insured_relationship',\n",
        "    'incident_type', 'collision_type',\n",
        "    'incident_severity', 'authorities_contacted',\n",
        "    'incident_state', 'incident_city',\n",
        "    'property_damage', 'police_report_available',\n",
        "    'zip_prefix', 'umbrella_limit',\n",
        "    'policy_deductable', 'auto_make_model'\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "m2qhK7alTUgq"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# preprocessing dalam pipeline (menghindari leakage)\n",
        "# =========================\n",
        "\n",
        "# kolom yang akan di encoding\n",
        "te_cols = [c for c in ['zip_prefix', 'auto_make_model', 'insured_hobbies', 'insured_occupation'] if c in X_train.columns]\n",
        "\n",
        "ordinal_cols = [c for c in ['insured_education_level', 'incident_severity', 'umbrella_limit', 'policy_deductable', 'policy_csl']\n",
        "                if c in X_train.columns]\n",
        "\n",
        "# nominal = kategorikal lain selain ordinal dan TE\n",
        "all_cat = [c for c in categorical_cols_raw if c in X_train.columns]\n",
        "nominal_cols = [c for c in all_cat if c not in set(te_cols + ordinal_cols)]\n",
        "\n",
        "# numerik\n",
        "num_cols = [c for c in numeric_cols_raw if c in X_train.columns]\n",
        "\n",
        "# ---- Pipeline per tipe fitur ----\n",
        "num_pipe = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", RobustScaler())\n",
        "])\n",
        "\n",
        "te_pipe = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"te\", ce.TargetEncoder(handle_unknown=\"value\", handle_missing=\"value\")) #handle_missing=\"value\" artinya missing value pakai nilai global mean\n",
        "])\n",
        "\n",
        "# ORDINAL\n",
        "transformers = []\n",
        "\n",
        "if num_cols:\n",
        "    transformers.append((\"num\", num_pipe, num_cols))\n",
        "\n",
        "if te_cols:\n",
        "    transformers.append((\"te\", te_pipe, te_cols))\n",
        "\n",
        "# insured_education_level\n",
        "if 'insured_education_level' in ordinal_cols:\n",
        "    edu_order = ['High School', 'College', 'Associate', 'Masters', 'MD', 'JD', 'PhD']\n",
        "    edu_pipe = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"ord\", OrdinalEncoder(categories=[edu_order], handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
        "    ])\n",
        "    transformers.append((\"edu_ord\", edu_pipe, ['insured_education_level']))\n",
        "\n",
        "# incident_severity\n",
        "if 'incident_severity' in ordinal_cols:\n",
        "    sev_order = ['Trivial Damage', 'Minor Damage', 'Major Damage', 'Total Loss']\n",
        "    sev_pipe = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"ord\", OrdinalEncoder(categories=[sev_order], handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
        "    ])\n",
        "    transformers.append((\"sev_ord\", sev_pipe, ['incident_severity']))\n",
        "\n",
        "# umbrella_limit\n",
        "if 'umbrella_limit' in ordinal_cols:\n",
        "    umbrella_order = [0, 1000000, 2000000, 3000000, 4000000, 5000000, 6000000, 7000000, 8000000, 9000000, 10000000]\n",
        "    umb_pipe = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"ord\", OrdinalEncoder(categories=[umbrella_order], handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
        "    ])\n",
        "    transformers.append((\"umb_ord\", umb_pipe, ['umbrella_limit']))\n",
        "\n",
        "# policy_deductable\n",
        "if 'policy_deductable' in ordinal_cols:\n",
        "    deductible_order = [500, 1000, 2000]\n",
        "    ded_pipe = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"ord\", OrdinalEncoder(categories=[deductible_order], handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
        "    ])\n",
        "    transformers.append((\"ded_ord\", ded_pipe, ['policy_deductable']))\n",
        "\n",
        "# policy_csl\n",
        "if 'policy_csl' in ordinal_cols:\n",
        "    csl_order = ['100/300', '250/500', '500/1000']\n",
        "    csl_pipe = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"ord\", OrdinalEncoder(categories=[csl_order], handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
        "    ])\n",
        "    transformers.append((\"csl_ord\", csl_pipe, ['policy_csl']))\n",
        "\n",
        "# OneHot untuk nominal\n",
        "if nominal_cols:\n",
        "    ohe_pipe = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\"))\n",
        "    ])\n",
        "    transformers.append((\"nom_ohe\", ohe_pipe, nominal_cols))\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=transformers,\n",
        "    remainder=\"drop\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simpan pipeline yang BELUM DI-FIT\n",
        "with open(\"preprocessing_pipeline.pkl\", \"wb\") as f:\n",
        "    pickle.dump(preprocess, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCLSnnqXgv2H",
        "outputId": "af3ab9a6-169b-4808-88be-02e2ae486d21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "months_as_customer\n",
            "age\n",
            "policy_annual_premium\n",
            "capital-gains\n",
            "capital-loss\n",
            "incident_hour_of_the_day\n",
            "number_of_vehicles_involved\n",
            "bodily_injuries\n",
            "witnesses\n",
            "total_claim_amount\n",
            "injury_claim\n",
            "property_claim\n",
            "vehicle_claim\n",
            "auto_year\n",
            "days_since_policy\n",
            "high_claim_without_witnesses\n",
            "no_police_report_but_severe_damage\n",
            "unknown_police_report_but_severe_damage\n",
            "unknown_property_damage\n",
            "unknown_collision_type\n",
            "multi_vehicles_no_injury\n",
            "zip_prefix\n",
            "auto_make_model\n",
            "insured_hobbies\n",
            "insured_occupation\n",
            "insured_education_level\n",
            "incident_severity\n",
            "umbrella_limit\n",
            "policy_deductable\n",
            "policy_csl\n",
            "policy_state_IN\n",
            "policy_state_OH\n",
            "insured_sex_MALE\n",
            "insured_relationship_not-in-family\n",
            "insured_relationship_other-relative\n",
            "insured_relationship_own-child\n",
            "insured_relationship_unmarried\n",
            "insured_relationship_wife\n",
            "incident_type_Parked Car\n",
            "incident_type_Single Vehicle Collision\n",
            "incident_type_Vehicle Theft\n",
            "collision_type_Rear Collision\n",
            "collision_type_Side Collision\n",
            "authorities_contacted_Fire\n",
            "authorities_contacted_Other\n",
            "authorities_contacted_Police\n",
            "authorities_contacted_UNKNOWN\n",
            "incident_state_NY\n",
            "incident_state_OH\n",
            "incident_state_PA\n",
            "incident_state_SC\n",
            "incident_state_VA\n",
            "incident_state_WV\n",
            "incident_city_Columbus\n",
            "incident_city_Hillsdale\n",
            "incident_city_Northbend\n",
            "incident_city_Northbrook\n",
            "incident_city_Riverwood\n",
            "incident_city_Springfield\n",
            "property_damage_YES\n",
            "police_report_available_YES\n"
          ]
        }
      ],
      "source": [
        "# NOTE: fit ini HANYA untuk inspeksi feature names,\n",
        "# pipeline training & CV tetap fit ulang secara aman\n",
        "preprocess.fit(X_train, y_train)\n",
        "\n",
        "def get_feature_names(preprocessor):\n",
        "    feature_names = []\n",
        "\n",
        "    for name, transformer, cols in preprocessor.transformers_:\n",
        "        if transformer == 'drop':\n",
        "            continue\n",
        "\n",
        "        # kalau pipeline\n",
        "        if hasattr(transformer, 'named_steps'):\n",
        "            last_step = list(transformer.named_steps.values())[-1]\n",
        "\n",
        "            # OneHotEncoder\n",
        "            if isinstance(last_step, OneHotEncoder):\n",
        "                ohe_features = last_step.get_feature_names_out(cols)\n",
        "                feature_names.extend(ohe_features)\n",
        "\n",
        "            # TargetEncoder / OrdinalEncoder / scaler\n",
        "            else:\n",
        "                feature_names.extend(cols)\n",
        "\n",
        "        else:\n",
        "            feature_names.extend(cols)\n",
        "\n",
        "    return feature_names\n",
        "\n",
        "feature_names = get_feature_names(preprocess)\n",
        "for f in feature_names:\n",
        "    print(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simpan feature_names terpisah (opsional, untuk analisis)\n",
        "with open(\"feature_names.pkl\", \"wb\") as f:\n",
        "    pickle.dump(feature_names, f)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "5S2kfoVUNxlE",
        "jKJ0uKdQOJ5r",
        "oqdVIcV-Pt3b",
        "0XxKmw4MPIro",
        "hXkiWKepR8xo",
        "yvuDIklfRjEG",
        "kvaStj2LPCcR",
        "xnOzEMAGOqu5",
        "5v0EEIxHw0ez"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
